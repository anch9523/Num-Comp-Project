{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: word2vec -train example/data/text8 -output example/data/text8.bin -size 500 -window 5 -sample 1e-3 -hs 0 -negative 5 -threads 12 -iter 5 -min-count 5 -alpha 0.025 -debug 2 -binary 1 -cbow 1\n",
      "Starting training using file example/data/text8\n",
      "Vocab size: 71291\n",
      "Words in train file: 16718843\n",
      "Alpha: 0.000002  Progress: 100.02%  Words/thread/sec: 198.66k  .34%  Words/thread/sec: 156.34k   Words/thread/sec: 180.55k  thread/sec: 192.75k  d/sec: 194.20k  /sec: 182.08k  3%  Words/thread/sec: 188.88k  190.85k    .48%  Words/thread/sec: 194.94k  ha: 0.024610  Progress: 1.57%  Words/thread/sec: 189.98k  24560  Progress: 1.77%  Words/thread/sec: 195.21k   195.00k   Progress: 1.98%  Words/thread/sec: 198.31k  ress: 2.08%  Words/thread/sec: 194.99k  ess: 2.18%  Words/thread/sec: 193.64k  ead/sec: 196.05k  read/sec: 198.10k  2.39%  Words/thread/sec: 196.53k  4343  Progress: 2.64%  Words/thread/sec: 194.84k  .024324  Progress: 2.72%  Words/thread/sec: 197.83k  thread/sec: 194.66k  ress: 2.90%  Words/thread/sec: 198.89k  /sec: 196.94k    Progress: 3.05%  Words/thread/sec: 199.32k  Progress: 3.55%  Words/thread/sec: 196.33k  98  Progress: 4.42%  Words/thread/sec: 199.16k  sec: 198.83k  hread/sec: 199.06k  gress: 5.99%  Words/thread/sec: 199.44k  Words/thread/sec: 199.34k  hread/sec: 199.78k  Progress: 6.43%  Words/thread/sec: 199.29k  sec: 198.55k  .023221  Progress: 7.13%  Words/thread/sec: 199.38k  %  Words/thread/sec: 199.55k  9.72k    Progress: 8.98%  Words/thread/sec: 199.61k  9%  Words/thread/sec: 199.49k  ds/thread/sec: 199.55k  .66%  Words/thread/sec: 199.32k  : 200.10k  read/sec: 199.77k  Words/thread/sec: 199.67k  %  Words/thread/sec: 199.88k  0.022249  Progress: 11.02%  Words/thread/sec: 199.70k  ogress: 11.54%  Words/thread/sec: 199.69k  .021987  Progress: 12.06%  Words/thread/sec: 200.39k  83k  12.87%  Words/thread/sec: 199.45k  021768  Progress: 12.94%  Words/thread/sec: 200.07k  3%  Words/thread/sec: 199.56k   Words/thread/sec: 200.08k  ords/thread/sec: 199.94k  13.40%  Words/thread/sec: 199.97k   13.44%  Words/thread/sec: 200.34k  Words/thread/sec: 200.43k  Words/thread/sec: 199.89k  15.03%  Words/thread/sec: 199.81k   Words/thread/sec: 200.00k  1%  Words/thread/sec: 200.20k   Words/thread/sec: 200.57k  : 199.79k  ss: 16.48%  Words/thread/sec: 199.87k   0.020854  Progress: 16.60%  Words/thread/sec: 200.56k  32  Progress: 16.69%  Words/thread/sec: 200.05k  ress: 17.22%  Words/thread/sec: 200.60k   17.90%  Words/thread/sec: 199.92k  lpha: 0.020374  Progress: 18.51%  Words/thread/sec: 199.94k  s/thread/sec: 199.75k  ess: 19.53%  Words/thread/sec: 199.73k  62  Progress: 19.76%  Words/thread/sec: 200.42k  : 200.23k  ha: 0.020000  Progress: 20.01%  Words/thread/sec: 199.98k  thread/sec: 200.25k   Progress: 21.24%  Words/thread/sec: 200.03k  00.18k  .44%  Words/thread/sec: 200.00k  s/thread/sec: 200.03k  9319  Progress: 22.78%  Words/thread/sec: 199.98k   Words/thread/sec: 199.63k  : 0.019261  Progress: 22.97%  Words/thread/sec: 199.89k  : 23.16%  Words/thread/sec: 199.97k  199.80k   23.66%  Words/thread/sec: 200.23k  Progress: 24.12%  Words/thread/sec: 200.20k  ha: 0.018835  Progress: 24.67%  Words/thread/sec: 199.68k  18689  Progress: 25.26%  Words/thread/sec: 199.55k    Words/thread/sec: 199.74k  ss: 26.13%  Words/thread/sec: 199.89k   199.74k  /thread/sec: 199.54k  hread/sec: 200.06k  ha: 0.018369  Progress: 26.54%  Words/thread/sec: 199.45k  %  Words/thread/sec: 199.56k  Progress: 27.14%  Words/thread/sec: 199.47k  6k  8.32%  Words/thread/sec: 199.56k  ha: 0.017770  Progress: 28.93%  Words/thread/sec: 199.57k  rogress: 29.47%  Words/thread/sec: 199.59k  /thread/sec: 199.09k  read/sec: 199.31k  74%  Words/thread/sec: 199.38k  88%  Words/thread/sec: 199.26k  gress: 29.94%  Words/thread/sec: 199.61k  1k    Words/thread/sec: 199.36k  .017062  Progress: 31.76%  Words/thread/sec: 199.20k  d/sec: 199.21k  s: 32.82%  Words/thread/sec: 199.46k  gress: 32.97%  Words/thread/sec: 199.30k  hread/sec: 199.23k    Progress: 33.17%  Words/thread/sec: 198.96k  016709  Progress: 33.18%  Words/thread/sec: 198.92k  3.96%  Words/thread/sec: 198.95k  read/sec: 199.08k   199.13k   198.90k  .015949  Progress: 36.23%  Words/thread/sec: 198.80k  03k   36.37%  Words/thread/sec: 198.77k    : 199.03k  ec: 198.62k  198.59k  536  Progress: 37.87%  Words/thread/sec: 198.50k  65%  Words/thread/sec: 198.54k  : 0.015187  Progress: 39.27%  Words/thread/sec: 198.49k  k  c: 198.44k  thread/sec: 198.64k   Progress: 40.56%  Words/thread/sec: 198.69k  98.64k  .78%  Words/thread/sec: 198.65k  a: 0.014405  Progress: 42.39%  Words/thread/sec: 198.56k  c: 198.45k  8.33k  /thread/sec: 198.52k  0%  Words/thread/sec: 198.64k  ess: 43.40%  Words/thread/sec: 198.30k  01  Progress: 43.61%  Words/thread/sec: 198.53k  2%  Words/thread/sec: 198.21k  013861  Progress: 44.57%  Words/thread/sec: 198.50k  45.05%  Words/thread/sec: 198.31k  ess: 45.55%  Words/thread/sec: 198.22k  98.35k     Words/thread/sec: 198.07k  d/sec: 198.16k  rogress: 46.45%  Words/thread/sec: 198.25k  ess: 46.63%  Words/thread/sec: 198.33k  .013340  Progress: 46.65%  Words/thread/sec: 198.39k  ad/sec: 198.31k  : 0.013051  Progress: 47.81%  Words/thread/sec: 198.13k  gress: 48.29%  Words/thread/sec: 198.17k  thread/sec: 198.01k   0.012653  Progress: 49.40%  Words/thread/sec: 198.17k  0.012582  Progress: 49.68%  Words/thread/sec: 198.24k  ead/sec: 198.20k    496  Progress: 50.03%  Words/thread/sec: 197.91k  c: 198.05k  s: 50.63%  Words/thread/sec: 197.90k  21  Progress: 51.13%  Words/thread/sec: 197.95k  hread/sec: 197.92k  : 52.14%  Words/thread/sec: 197.98k  c: 197.96k    Words/thread/sec: 197.90k  011776  Progress: 52.91%  Words/thread/sec: 197.85k  : 198.06k  lpha: 0.011731  Progress: 53.09%  Words/thread/sec: 197.94k  rds/thread/sec: 197.87k  s/thread/sec: 198.00k  ords/thread/sec: 198.11k  84k    Progress: 53.53%  Words/thread/sec: 197.89k  ec: 197.78k   54.57%  Words/thread/sec: 197.76k  ess: 55.14%  Words/thread/sec: 197.97k      Progress: 56.03%  Words/thread/sec: 197.83k  hread/sec: 197.91k    Words/thread/sec: 197.67k  thread/sec: 197.64k  ss: 56.56%  Words/thread/sec: 197.77k   ords/thread/sec: 197.75k  0406  Progress: 58.39%  Words/thread/sec: 197.73k  ec: 197.59k  .39%  Words/thread/sec: 197.51k  3%  Words/thread/sec: 197.62k  ess: 59.65%  Words/thread/sec: 197.60k  39  Progress: 59.86%  Words/thread/sec: 197.54k  a: 0.009983  Progress: 60.08%  Words/thread/sec: 197.46k  hread/sec: 197.39k  197.47k  /thread/sec: 197.42k  ds/thread/sec: 197.30k   Progress: 62.77%  Words/thread/sec: 197.31k  272  Progress: 62.93%  Words/thread/sec: 197.25k  sec: 197.36k  pha: 0.009221  Progress: 63.13%  Words/thread/sec: 197.37k  d/sec: 197.42k  7.44k  s: 63.63%  Words/thread/sec: 197.46k  90  Progress: 64.05%  Words/thread/sec: 197.40k  %  Words/thread/sec: 197.43k  : 197.34k  /thread/sec: 197.40k  k  97.55k  sec: 197.51k  ead/sec: 197.30k  7.37k   Words/thread/sec: 197.44k   Words/thread/sec: 197.37k  7.34k  40%  Words/thread/sec: 197.34k  02  Progress: 68.80%  Words/thread/sec: 197.52k  : 197.48k  0.007653  Progress: 69.50%  Words/thread/sec: 197.51k  thread/sec: 197.39k  Progress: 69.79%  Words/thread/sec: 197.46k  1%  Words/thread/sec: 197.50k   0.007397  Progress: 70.43%  Words/thread/sec: 197.52k  ead/sec: 197.51k  ogress: 71.64%  Words/thread/sec: 197.51k  46k   Words/thread/sec: 197.53k  7%  Words/thread/sec: 197.48k   ress: 73.05%  Words/thread/sec: 197.40k  690  Progress: 73.25%  Words/thread/sec: 197.47k  ha: 0.006639  Progress: 73.46%  Words/thread/sec: 197.58k  read/sec: 197.49k  0.006383  Progress: 74.48%  Words/thread/sec: 197.50k  k  1k  ds/thread/sec: 197.59k  5931  Progress: 76.29%  Words/thread/sec: 197.60k  pha: 0.005880  Progress: 76.49%  Words/thread/sec: 197.45k  55  Progress: 76.59%  Words/thread/sec: 197.61k  7.52k  05704  Progress: 77.20%  Words/thread/sec: 197.61k  97.58k  : 0.005448  Progress: 78.22%  Words/thread/sec: 197.54k  197.63k  .58k  7.68k  ds/thread/sec: 197.62k  ad/sec: 197.68k  pha: 0.004991  Progress: 80.05%  Words/thread/sec: 197.65k  80.43%  Words/thread/sec: 197.77k  0.004772  Progress: 80.92%  Words/thread/sec: 197.74k  72k  pha: 0.004492  Progress: 82.05%  Words/thread/sec: 197.74k  004381  Progress: 82.49%  Words/thread/sec: 197.74k   197.94k  read/sec: 197.89k   Words/thread/sec: 197.80k  Progress: 83.69%  Words/thread/sec: 197.92k  7.95k  90%  Words/thread/sec: 197.97k  : 0.003624  Progress: 85.52%  Words/thread/sec: 197.98k  read/sec: 198.00k   86.53%  Words/thread/sec: 198.04k  : 0.003263  Progress: 86.96%  Words/thread/sec: 198.01k  /sec: 197.95k  ess: 88.15%  Words/thread/sec: 197.95k    Words/thread/sec: 197.99k  02510  Progress: 89.97%  Words/thread/sec: 198.09k  98.13k  c: 198.16k  Progress: 91.44%  Words/thread/sec: 198.02k  .14k  8.02k  rds/thread/sec: 198.11k  ogress: 93.39%  Words/thread/sec: 198.09k  /sec: 198.15k  thread/sec: 198.17k  9%  Words/thread/sec: 198.10k   0.001133  Progress: 95.48%  Words/thread/sec: 198.16k  s/thread/sec: 198.17k  .20k  5%  Words/thread/sec: 198.25k   0.000587  Progress: 97.67%  Words/thread/sec: 198.24k  ead/sec: 198.26k  ogress: 98.91%  Words/thread/sec: 198.35k  46k  "
     ]
    }
   ],
   "source": [
    "# Setup - train model \n",
    "word2vec.word2vec('example/data/text8', 'example/data/text8.bin', size=500, binary=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.load('example/data/text8.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is application. Model guessed correctly.\n",
      "Correct answer is car. Model guessed correctly.\n",
      "Correct answer is council. Model guessed correctly.\n",
      "Correct answer is day. Model guessed months\n",
      "Correct answer is department. Model guessed offices\n",
      "Correct answer is difference. Model guessed correctly.\n",
      "Correct answer is event. Model guessed correctly.\n",
      "Correct answer is fact. Model guessed explanation\n",
      "Correct answer is god. Model guessed goddess\n",
      "Correct answer is hour. Model guessed correctly.\n",
      "Correct answer is language. Model guessed correctly.\n",
      "Correct answer is member. Model guessed correctly.\n",
      "Correct answer is night. Model guessed wednesday\n",
      "Correct answer is period. Model guessed correctly.\n",
      "Correct answer is population. Model guessed correctly.\n",
      "Correct answer is product. Model guessed correctly.\n",
      "Correct answer is river. Model guessed correctly.\n",
      "Correct answer is role. Model guessed correctly.\n",
      "Correct answer is solution. Model guessed correctly.\n",
      "Correct answer is street. Model guessed correctly.\n",
      "Correct answer is system. Model guessed correctly.\n",
      "Correct answer is town. Model guessed correctly.\n",
      "Correct answer is version. Model guessed correctly.\n",
      "Correct answer is website. Model guessed correctly.\n",
      "Correct answer is year. Model guessed correctly.\n",
      "Accuracy rate:  80.0 %\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "countTotal = 0\n",
    "correctCount = 0\n",
    "incorrectCount = 0\n",
    "unrecognizedCount = 0\n",
    "\n",
    "# Change file name to run experiment on different analogy sets \n",
    "with open('./Bigger Analogy Test Set/1_Inflectional_morphology/I01 [noun - plural_reg].txt') as file:\n",
    "    for line1,line2 in itertools.zip_longest(*[file]*2):\n",
    "        line1 = line1.split('\\t')\n",
    "        line2 = line2.split('\\t')\n",
    "        line1[1] = line1[1].split('/')\n",
    "        for i in range(len(line1[1])):\n",
    "            line1[1][i] = line1[1][i].rstrip()\n",
    "            if line1[1][i].__contains__('-'):\n",
    "                line1[1].pop(i)\n",
    "        line2[1] = line2[1].split('/')\n",
    "        for i in range(len(line2[1])):\n",
    "            line2[1][i] = line2[1][i].rstrip()\n",
    "            if line2[1][i].__contains__('-'):\n",
    "                line2[1].pop(i)\n",
    "        countTotal += 1\n",
    "        try:\n",
    "            line2[1].append(line1[0])\n",
    "            indexes, metrics = model.analogy(pos=line2[1], neg=line1[1])\n",
    "            if (model.vocab[indexes].__contains__(line2[0])):\n",
    "                correctCount += 1\n",
    "                print(\"Correct answer is \" + line2[0] + \". Model guessed correctly.\")\n",
    "            else:\n",
    "                incorrectCount += 1\n",
    "                print(\"Correct answer is \" + line2[0] + \". Model guessed \" + model.vocab[indexes][0])\n",
    "        except Exception as e:\n",
    "             unrecognizedCount += 1\n",
    "             print(\"Correct answer is \" + line2[0] + \". Model did not recognize the word \" + e.args[0])\n",
    "        #print(line1[0], line1[1], line2[0], line2[1])\n",
    "    print(\"Accuracy rate: \", correctCount/countTotal*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcrUlEQVR4nO3df5xVVb3/8dcHBgEVVHRSi2jEhFQgxBm8ZAmIFy29YuolBMvRiLyZipap34pLaolFNxMx44YSQmbiz7DrxUAxfyQy/FAITQU0tKsIDyx/IDJ8vn+sNcNhOD9mzjnMsOr9fDx4sM86++y99j7rvM86a/8Yc3dERCQ97dq6AiIiUhwFuIhIohTgIiKJUoCLiCRKAS4ikqiK1lzZAQcc4FVVVa25ShGR5NXV1b3p7pVNy1s1wKuqqli8eHFrrlJEJHlm9nK2cg2hiIgkSgEuIpIoBbiISKJadQw8mw8++IB169axefPmtq6K7CY6depE9+7d6dChQ1tXRWS31uYBvm7dOrp06UJVVRVm1tbVkTbm7mzYsIF169ZxyCGHtHV1RHZrbT6EsnnzZvbff3+FtwBgZuy///76RSbSDG0e4IDCW3ag9iDSPLtFgIuISMu1+Rh4U1VXPFDW5a2ddHLBecyMSy+9lB//+McATJ48mbfffpuJEyeWvP7a2lpOOeUUzjzzzJKXlc+dd97JhAkTOOigg3j44Yd3eO6FF17gkksuYdWqVey777507dqV733vexx33HG7tE4ismvtdgHeFjp27Mjdd9/NlVdeyQEHHNDW1WlUX19P+/btmzXv9OnTuemmmxg6dOgO5Zs3b+bkk09m8uTJnHrqqQCsWLGCxYsXK8AlKeXu3O0qzek0louGUICKigrGjRvHT37yk52eq62tZc6cOY2P9957bwAeeeQRBg8ezMiRI+nVqxdXXHEFs2fPZuDAgfTt25eXXnqp8TW///3v+cxnPkOvXr2YO3cuEML5sssuo6amhn79+vHzn/+8cblDhw5l9OjR9O3bd6f63H777fTt25c+ffpw+eWXA3DVVVfx2GOPcf7553PZZZftMP/s2bMZNGhQY3gD9OnTh9raWgAmTpzI5MmTd3hu7dq1AMyaNYuBAwfSv39/vvrVr1JfX099fT21tbX06dOHvn37Nu6zG264gSOOOIJ+/foxatQoAN555x3OO+88ampqOOqoo7jvvvsAWLlyZeNy+/XrxwsvvFDoLRKRLNQDjy644AL69evHt771rWa/Zvny5axatYpu3brRs2dPxo4dy6JFi/jpT3/KlClTuP766wFYu3YtCxcu5KWXXmLo0KG8+OKLzJw5k3322Yenn36a999/n2OPPZbhw4cDsGjRIlasWLHTaXSvvfYal19+OXV1dey3334MHz6ce++9lwkTJrBgwQImT55MdXX1Dq9ZuXIlAwYMaPH+WLVqFXfccQePP/44HTp04Gtf+xqzZ8/myCOP5NVXX2XFihUAbNq0CYBJkyaxZs0aOnbs2Fj2/e9/n+OPP55bbrmFTZs2MXDgQE444QRuvvlmLr74YsaMGcOWLVuor69vcf1ERD3wRl27duVLX/oSN9xwQ7NfU1NTw8EHH0zHjh059NBDGwO4b9++jb1YgJEjR9KuXTsOO+wwevbsyXPPPce8efOYOXMm/fv355hjjmHDhg2NPdGBAwdmPQf66aefZsiQIVRWVlJRUcGYMWN49NFHW7Sdn//85+nTpw+nn3563vnmz59PXV0dNTU19O/fn/nz57N69Wp69uzJ6tWrufDCC3nwwQfp2rUrAP369WPMmDHMmjWLiorQL5g3bx6TJk2if//+DBkyhM2bN/PKK68waNAgfvCDH3Ddddfx8ssv07lz5xZtg4gECvAM48ePZ/r06bzzzjuNZRUVFWzbtg0IF5ls2bKl8bmOHTs2Trdr167xcbt27di6dWvjc01PizMz3J0pU6awbNkyli1bxpo1axq/APbaa6+s9SvmD1AfeeSRLFmypPHxPffcw4wZM9i4ceNO2wc0nn/t7pxzzjmN9Xv++eeZOHEi++23H8uXL2fIkCFMnTqVsWPHAvDAAw9wwQUXUFdXx9FHH83WrVtxd+66667GZbzyyiscfvjhjB49mvvvv5/OnTtz4oknsmDBghZvl4gowHfQrVs3Ro4cyfTp0xvLqqqqqKurA+C+++7jgw8+aPFy77zzTrZt28ZLL73E6tWr6d27NyeeeCI/+9nPGpf35z//eYcvjmyOOeYYFi5cyJtvvkl9fT233347gwcPzvua0aNH8/jjj3P//fc3lr377rs7bF9DwC9ZsoQ1a9YAMGzYMObMmcMbb7wBwMaNG3n55Zd588032bZtG2eccQZXX301S5YsYdu2bfzlL39h6NCh/PCHP2TTpk28/fbbnHjiiUyZMqXxi2fp0qUAjT35iy66iFNPPZVnnnmmJbtTRKLdbgy8NY/gZvONb3yDG2+8sfHxV77yFUaMGMHAgQMZNmxYzt5xPr1792bw4MG8/vrr3HzzzXTq1ImxY8eydu1aBgwYgLtTWVnJvffem3c5Bx98MNdeey1Dhw7F3fnc5z7HiBEj8r6mc+fOzJ07l0svvZTx48dz4IEH0qVLF77zne8AcMYZZzQO5dTU1NCrVy8AjjjiCK655hqGDx/Otm3b6NChA1OnTqVz586ce+65jb32a6+9lvr6es4++2zeeust3J1LLrmEfffdl+9+97uMHz+efv364e5UVVUxd+5c7rjjDmbNmkWHDh046KCDmDBhQov3qYiAFfOzvFjV1dXe9A86rFq1isMPP7zV6iBpULuQpv6ZTyM0szp3r25ariEUEZFEKcBFRBK1WwR4aw7jyO5P7UGkedo8wDt16sSGDRv0oRVg+/3AO3Xq1NZVEdntFTwLxcxuAU4B3nD3PrHsR8C/AVuAl4Bz3X1TMRXo3r0769atY/369cW8XP4BNfxFHhHJrzmnEc4AbgRmZpQ9BFzp7lvN7DrgSuDyYirQoUMH/eUVEZEiFBxCcfdHgY1Nyua5e8Olhn8E1F0SEWll5RgDPw/4nzIsR0REWqCkADezbwNbgdl55hlnZovNbLHGuUVEyqfoADezcwgHN8d4nlNI3H2au1e7e3VlZWWxqxMRkSaKuheKmZ1EOGg52N3fLTS/iIiUX8EeuJndDjwJ9DazdWb2ZcJZKV2Ah8xsmZndvIvrKSIiTRTsgbv7WVmKp2cpExGRVtTmV2KKiEhxFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJKpggJvZLWb2hpmtyCjrZmYPmdkL8f/9dm01RUSkqeb0wGcAJzUpuwKY7+6HAfPjYxERaUUFA9zdHwU2NikeAfwyTv8SOK281RIRkUKKHQM/0N3/ChD//1D5qiQiIs2xyw9imtk4M1tsZovXr1+/q1cnIvJPo9gAf93MDgaI/7+Ra0Z3n+bu1e5eXVlZWeTqRESkqWID/H7gnDh9DnBfeaojIiLN1ZzTCG8HngR6m9k6M/syMAn4VzN7AfjX+FhERFpRRaEZ3P2sHE8NK3NdRESkBXQlpohIohTgIiKJUoCLiCRKAS4ikigFuIhIohTgIiKJUoCLiCRKAS4ikigFuIhIohTgIiKJUoCLiCRKAS4ikigFuIhIohTgIiKJUoCLiCRKAS4ikigFuIhIohTgIiKJUoCLiCRKAS4ikigFuIhIohTgIiKJUoCLiCSqpAA3s0vMbKWZrTCz282sU7kqJiIi+RUd4Gb2EeAioNrd+wDtgVHlqpiIiORX6hBKBdDZzCqAPYHXSq+SiIg0R0WxL3T3V81sMvAK8B4wz93nNZ3PzMYB4wB69OhR7OpEklN1xQNtXYVmWTvp5LaughSplCGU/YARwCHAh4G9zOzspvO5+zR3r3b36srKyuJrKiIiOyhlCOUEYI27r3f3D4C7gU+Vp1oiIlJIKQH+CvAvZranmRkwDFhVnmqJiEghRQe4uz8FzAGWAM/GZU0rU71ERKSAog9iArj7fwL/Waa6iIhIC+hKTBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUlUSQFuZvua2Rwze87MVpnZoHJVTERE8qso8fU/BR509zPNbA9gzzLUSUREmqHoADezrsBxQC2Au28BtpSnWiIiUkgpPfCewHrgVjP7JFAHXOzu72TOZGbjgHEAPXr0KGF10hqqrnigratQ0NpJJ7d1FUR2C6WMgVcAA4CfuftRwDvAFU1ncvdp7l7t7tWVlZUlrE5ERDKVEuDrgHXu/lR8PIcQ6CIi0gqKDnB3/z/gL2bWOxYNA/5UllqJiEhBpZ6FciEwO56Bsho4t/QqiYhIc5QU4O6+DKguT1VERKQldCWmiEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJKrkADez9ma21MzmlqNCIiLSPOXogV8MrCrDckREpAVKCnAz6w6cDPyiPNUREZHmqijx9dcD3wK65JrBzMYB4wB69OhR4up2VnXFA2Vf5q6wdtLJbV0FEfkHU3QP3MxOAd5w97p887n7NHevdvfqysrKYlcnIiJNlDKEcixwqpmtBX4NHG9ms8pSKxERKajoAHf3K929u7tXAaOABe5+dtlqJiIieek8cBGRRJV6EBMAd38EeKQcyxIRkeZRD1xEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSpQAXEUmUAlxEJFEKcBGRRCnARUQSVXSAm9lHzexhM1tlZivN7OJyVkxERPKrKOG1W4FvuPsSM+sC1JnZQ+7+pzLVTURE8ii6B+7uf3X3JXH678Aq4CPlqpiIiORXljFwM6sCjgKeyvLcODNbbGaL169fX47ViYgIZQhwM9sbuAsY7+5/a/q8u09z92p3r66srCx1dSIiEpUU4GbWgRDes9397vJUSUREmqOUs1AMmA6scvf/Kl+VRESkOUrpgR8LfBE43syWxX+fK1O9RESkgKJPI3T3xwArY11ERKQFdCWmiEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJEoBLiKSKAW4iEiiFOAiIolSgIuIJKqkADezk8zseTN70cyuKFelRESksKID3MzaA1OBzwJHAGeZ2RHlqpiIiORXSg98IPCiu6929y3Ar4ER5amWiIgUYu5e3AvNzgROcvex8fEXgWPc/etN5hsHjIsPewPPF1/dVnMA8GZbV+IfiPZn+Whfllcq+/Nj7l7ZtLCihAValrKdvg3cfRowrYT1tDozW+zu1W1dj38U2p/lo31ZXqnvz1KGUNYBH8143B14rbTqiIhIc5US4E8Dh5nZIWa2BzAKuL881RIRkUKKHkJx961m9nXgf4H2wC3uvrJsNWtbSQ35JED7s3y0L8sr6f1Z9EFMERFpW7oSU0QkUQpwEZFEtXmAm9nnzczN7BNtWIdaM/twEa8728yeMbOVZrbczH5hZvvugiq2mJnVm9kyM1thZr8tVC8zm2hm3ywwz2nFXG1rZm/nKD/QzH5lZqvNrM7MnjSzz7d0+btCrjrvLsxsvJntmeO5CjP7gZm9ENvAMjP7dmvXsUmd3Mx+nPH4m2Y2scBrcra32F5fjdv2JzM7q8xVbrH4+S/panQzqzKzFc2dv80DHDgLeIxwFssuEy/9z6UWaFGAm9lJwCXAZ939SGAA8ARwYLF1LLP33L2/u/cBNgIXlGGZpxFum1AyMzPgXuBRd+/p7kcT2kD3cix/d2ZmFfkeN9N4IGuAA9cQ2nNfd+8PfAboUMQ6yul94HQzO6AFrzmN/O3tJ3H7RgA/N7M23UZ3H+vuf2rtlbbZP2Bv4FWgF/BcRnl7YDLwLPAMcGEsryGE5HJgEdCFEL43Zrx2LjAkTr8NXAU8BXwamEA4/XEF4eizAWfG+Z4HlgGdgaOBhUAd4Sybg7PU/Q/A0DzbthY4IE5XA4/E6b2AW2I9lgIjYvmRcZuWxW0+LM77QNzeFcAXWrBv386YPh+4KU4fCjwYt+0PwCdi+UTgm3H6K7F+y4G7CEHxKcIXwZpYx0PzLOsQ4Mm4jKsz65JRp2HAwjz1z/e+Do/LXwLcCewdyycBf4r7b3Is+/e475YTvixatP+AIcAjwBzgOWA22w/+Z2uPnYBbCW13aUMbidtzJ/BbYEGWx7naxU6fBeAiYEsse7hJvfcENgBdcmxXFbAi4/E3gYkF2sZO+5As7bXQ/gSuBL6fZb0fA+bH5cwHepClvTVZ3kRie42P/w/4UJy+LO7HZ4DvZczzpVi2HLgt17oz9sUf43KuamZ7eITwWT811nkZIVfWxOez5kosX05o0z/KfH8KttNiw7cc/4Czgelx+glgQJz+D0JwVMTH3YA9gNVATSzrSjgNspbcH3QHRmY81y1j+jbg3zJ3fJzuEOtSGR9/gXCKZNO6bwT2ybNta8ke4D8Azo7T+wJ/Jnx4pwBjYvkehC+SM4D/zlhmzvXlCaD2hKA4KT6eT/ywAccAC5p+IID9M5ZzDdu/QGcAZ2Y8l2tZ9wNfitMXkD3ALyL0oFoU4IRLnx8F9orllxO+mLsRPiwNH6Z94//PAh/JLGvh/hsCvEX4ZdCO8CH7NLnb4zeAW2PZJ4BXCKFeS7j4rVvG9mU+ztUudvosNG1fTerdD1iaZ7uqyB3gud7PnfYhWdprof0Z99FaYJ8m6/0tcE6cPg+4N1t7a7K8iWxvrwOAP8Tp4WzvnLWL7eY4whfO82z/THYrsO65wFlx+vxC7aFpjmTU8zeEz0DOXCF8eQyO0y0K8FIupS+Hs4Dr4/Sv4+MlwAnAze6+FcDdN5pZX+Cv7v50LPsbQPglnlM9ofE3GGpm3yL0UroBKwlvYKbeQB/gobjs9sBf860k1u02Qg/s/7n7HXlmHw6cmjHe3InQ43gS+LaZdQfudvcXzOxZYLKZXQfMdfc/5KtHE53NbBnhA1sXt2dvQs/mzoz91jHLa/uY2TWEINmb0FvYQYFlHUv48oGwX64rVFkzm0oIxi3uXpNn1n8h/Kx+PK53D8K++xuwGfiFmT1A+AACPA7MMLPfAHcXqkcOi9x9XaznMsI+fYvs7fHThHDD3Z8zs5cJvzABHnL3jRnLzXycq13s9FloScXN7FzgYmB/wvuVa75872e2fbhTey1UF3f/m5nNJHx5v5fx1CDg9Dh9G/DDZmwawCVm9hWgJ3BSLBse/y2Nj/cm/Jr9JDDH3d+MdWnYj7nWPYgwhAPwK8KvoAbZ2sNjTSsXs+Y9d59qZn3Ikitmtg/hS3FhRh0+28ztb7sAN7P9geMJYeGEDfK40cbO91XJVgawlR3H8jtlTG929/q4vk7ATYRvyL/EAyiZ82auZ6W7DyqwCSsJ3/wPu/uzQH8zu5HQc25ar8z1GHCGuze9qdcqM3sKOBn4XzMb6+4LzOxo4HPAtWY2z92vKlCvBu+5e//YQOYSegEzgE0exg3zmQGc5u7LzayW0Otoql2BZWV7rzKtZHvI4+4XxPHRxbEo1/tqhODb6aCVmQ0kDM2MAr4OHO/u55vZMYT9uszM+rv7hgJ1a+r9jOl6wucmV3vM16N4J8/jrO0iHisotC8zvQj0MLMu7v53d78VuDUeGGtP7v2a8/3MsQ9/la29NqN+1xM6abfmmae52/sTd59sZqcDM83sUMJ+vNbdf545o5ld1MzlNmeebO1hB2Y2jDD0dFxDEVlyJZ5c0JL3dwdteRDzTGCmu3/M3avc/aOE8a5PA/OA8xsO7phZN8J404fNrCaWdYnPryWEZzsz+yjhNrfZNDTUN2Nv48yM5/5O6D1D+JlVaWaD4no6mNmRWZZ3LaF3nHnQrXPG9FrC2BZkBBWhN3th/GBiZkfF/3sCq939BsIQRD8LZ8a86+6zCD2AATm2LSd3f4vQ4/kmodezxsz+Pa7TzOyTWV7WhdA76ACMyShv3E+xx5lrWY+z/aB05uszLQA6mdl/ZJRlHpRbS/b39Y/AsWb28bjePc2sV3xP93H33xEO8PWPzx/q7k+5+wTCXecy799Tilzt8VHiNptZL0Ivujl34MzaLsj+WYAd22wjd38XmA7cGDstDQfw94izvA58yMz2N7OOwCnxdTnfz2z7MFt7bcY2NvR8fwN8OaP4CXZsLw292azbmGWZdxO++M8h7MfzYnvAzD5iZh8iDA+NjB3HzP2Ya91/ZPvntkUnWJjZxwidxZHu3vBLI2uuuPsm4K34y62hDs3WlgF+FnBPk7K7gNHALwhjh8+Y2XJgtId7jn8BmBLLHiKE8uOE4H+WEHJLsq0s7qj/jvPdSzg40WAGcHP8OdSeEO7XxfUsI8tPzxgUNwD/Y+E0picI38YNww3fA35qZn+I5Q2uJoyHPRN7RVfH8i8AK2IdPgHMBPoCi2LZtwnj0S3m7ksJB0lGERrIl+O2rST7Pdy/Szjw+xAhqBr8GrjMzJbG3k6uZV0MXGBmTxPGO7PVyQk/UQeb2RozWwT8kjCmDTneV3dfTxg/vt3MniF80D5B+KDPjWULCWcIAfzIzJ6N+/rRuB9Klqc93gS0tzD8dQdQ6+7v515So1ztYqfPQiyfRmh7D2dZ1rcJw34rzGwp4YDkL4HX3P0Dth/Yn8uO72+u9zPbPszWXpvrx4RjGQ0uAs6N790XCe0Hdm5v+VwFXAr8njDk8WR8D+YQDuiuBL4PLIzb918F1j0euDS2y4MJQ2bNVUsYsrrHwmmOv4vtJVeunAtMNbMn2XFoqSBdSi8i0oSFc+zfc3c3s1GEA5rZOjttqq0PYoqI7I6OJgxDGbCJcIbKbkc9cBGRRO0OV2KKiEgRFOAiIolSgIuIJEoBLkmy3eAuliJtTQEuqdrld7G0/HewFGlzCnBJTrzK7ljC1XyjYll7M5scLzh5xswujOU1ZvaEhfu1L4pXTNZauO1Bw/LmmtmQOP22mV1l4TLxQWY2wcyetnBf9WkZV0p+3Mx+H5e7xMwONbPbzGxExnJnm9mprbVf5J+PAlxSdBrwoLv/GdhoZgOAcYTb2B7l7v2A2Wa2B+FqyIvd/ZOEG0MVutJtL8Ld4I5x98cId0Ss8XBf9c7ES88JtxGdGpf7KcKVj78gXFWHhXvQfAr4Xbk2WqQpBbik6CzCZdaw/S6W2e7a15smdwxseD6PbHewfCpeln08cKSZdSHcXvWeuNzN7v5uvKPcx+O9N84C7mrG+kSKpisxJSmW4y6WhFvmttYdLPPdcfA2wj1FRrGbXr0n/zjUA5fU5LqL5RJa6Q6W8c5968zstLjcjrb971POINwIiXgDJZFdRgEuqcl1F8sP07p3sPwicFG8i90TwEHxNa8Dq8h/v2uRstC9UETKKPbEnyX8ecCW3IJUpMXUAxcpEzM7gTBsM0XhLa1BPXARkUSpBy4ikigFuIhIohTgIiKJUoCLiCRKAS4ikqj/DzYqYoyEH+VWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Accuracy':['Accurate Guess', 'Related Guess', 'Incorrect Guess', 'Not Recognized'], 'Number of Guesses':[correctCount, 6, incorrectCount, unrecognizedCount]})\n",
    "ax = df.plot.bar(x='Accuracy', y='Number of Guesses', rot=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Takeaways\n",
    "\n",
    "1. The model seems to perform much better on the **inflectional morphology** dataset. \n",
    "- This is likely an inherent quality of the word2vec model. \n",
    "- For context: **inflectional morphology** does not change the part of speech of a word, and is associated with relationships *between* words (ex. changing a verb from its singular form to plural form in order to match the subject of a sentence). In contrast, **derivational morphology** can often change the part of speech of a word, and is associated with semantic relationships *within* a word itself (ex. changing a verb to an adverb usually has no relationship to the rest of a sentence). [See this handout for more info.](http://websites.umich.edu/~jlawler/Inflection.pdf)\n",
    "- Because word2vec compares relationships *between* words, it seems inherently better suited to analyze these types of analogies. \n",
    "2. The impact of bias/variance can be seen in the results comparing accuracy across dimensional values. \n",
    "- In the case of 5-dimension vectors, the vectors are really too small to be of much use, resulting in extremely poor results (never scoring above 4% accuracy). The model is unable to distinguish relevant relationships between the words because the vectors are so small, resulting in a high degree of *bias*. Increasing the dimensions to 50 helps significantly, but issues still persist. \n",
    "- However, beyond about 1000-dimension vectors does not seem to increase the accuracy of the results and in fact seems to worsen the accuracy in certain cases. This is likely due to overfitting or *bias* with such large vectors. \n",
    "- Overall, anywhere from 500-1500 dimension vectors will likely provide a suitable model. \n",
    "3. The model's results are ***heavily*** dependent on the training data set. \n",
    "- Certain analogy sets were not usable because the words used did not appear in the training set, resulting in complete failure. \n",
    "- However, beyond just not including words in the training set, some relationships were indiscernable even if all words were in the training set. \n",
    "- An example of this is the UK city -> County data set, which associates cities in the UK with the county they are located in. The model recognized every word used in every analogy. However, the training set likely did not include any sentences indicating the relationship between these words as cities/counties, and thus the model was never able to get any of the analogies correct. \n",
    "- This has probably been discussed at length for machine learning algorithms in general, but still an important reminder that the biases present in the training data sets for these models will become very apparent when putting them into practice. Thus it is important to use a diverse and varied data set for these types of algorithms. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
