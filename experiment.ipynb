{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: word2vec -train example/data/text8 -output example/data/text8.bin -size 50 -window 5 -sample 1e-3 -hs 0 -negative 5 -threads 12 -iter 5 -min-count 5 -alpha 0.025 -debug 2 -binary 1 -cbow 1\n",
      "Starting training using file example/data/text8\n",
      "Vocab size: 71291\n",
      "Words in train file: 16718843\n",
      "Alpha: 0.000002  Progress: 100.04%  Words/thread/sec: 410.84k   0.024835  Progress: 0.67%  Words/thread/sec: 378.90k  785  Progress: 0.87%  Words/thread/sec: 393.97k  ogress: 1.08%  Words/thread/sec: 386.50k   Progress: 1.24%  Words/thread/sec: 389.37k  : 1.28%  Words/thread/sec: 386.35k  ec: 395.48k  024375  Progress: 2.51%  Words/thread/sec: 401.80k    Words/thread/sec: 404.18k  ha: 0.024100  Progress: 3.61%  Words/thread/sec: 405.41k  ss: 4.58%  Words/thread/sec: 407.16k  /sec: 408.80k  0.023549  Progress: 5.82%  Words/thread/sec: 408.50k  3%  Words/thread/sec: 408.51k  Progress: 6.99%  Words/thread/sec: 410.50k   %  Words/thread/sec: 410.40k  086  Progress: 7.67%  Words/thread/sec: 409.18k    Words/thread/sec: 409.56k  .022799  Progress: 8.82%  Words/thread/sec: 409.42k  9.32%  Words/thread/sec: 409.65k  86%  Words/thread/sec: 409.52k  4  Progress: 10.36%  Words/thread/sec: 409.61k   0.022363  Progress: 10.56%  Words/thread/sec: 410.26k  rds/thread/sec: 410.57k  ds/thread/sec: 410.52k  1k  sec: 410.55k  read/sec: 409.83k  1.03k  24k  2k  .021391  Progress: 14.45%  Words/thread/sec: 410.62k  lpha: 0.021267  Progress: 14.95%  Words/thread/sec: 410.83k  5.37%  Words/thread/sec: 410.49k  2.01k  thread/sec: 412.26k  6  Progress: 16.99%  Words/thread/sec: 412.01k  sec: 412.00k  s/thread/sec: 412.70k  7  Progress: 18.02%  Words/thread/sec: 412.41k   412.10k  19.24%  Words/thread/sec: 412.14k  pha: 0.020023  Progress: 19.92%  Words/thread/sec: 412.41k  ogress: 20.40%  Words/thread/sec: 412.41k  5%  Words/thread/sec: 411.75k   0.019662  Progress: 21.36%  Words/thread/sec: 411.52k  ead/sec: 411.51k  ogress: 22.57%  Words/thread/sec: 411.31k  25k  ess: 23.72%  Words/thread/sec: 411.97k  ss: 23.99%  Words/thread/sec: 412.16k    Words/thread/sec: 411.17k  ad/sec: 411.28k  ogress: 25.61%  Words/thread/sec: 411.19k  06k  /sec: 411.30k   411.28k  11.14k  : 0.018142  Progress: 27.44%  Words/thread/sec: 411.31k  : 0.018015  Progress: 27.95%  Words/thread/sec: 410.63k  1  Progress: 28.49%  Words/thread/sec: 411.07k  ess: 29.01%  Words/thread/sec: 410.85k  ead/sec: 410.87k  ess: 30.07%  Words/thread/sec: 410.66k  36%  Words/thread/sec: 410.54k  k   30.77%  Words/thread/sec: 410.75k  a: 0.017270  Progress: 30.93%  Words/thread/sec: 410.99k  ds/thread/sec: 410.62k  2.37%  Words/thread/sec: 410.40k  .28k  46%  Words/thread/sec: 410.42k  d/sec: 410.95k  /thread/sec: 411.13k  61%  Words/thread/sec: 410.24k  35.13%  Words/thread/sec: 410.57k  gress: 35.63%  Words/thread/sec: 410.81k  hread/sec: 410.37k  ec: 410.52k  /thread/sec: 410.42k  6%  Words/thread/sec: 410.73k   0.015511  Progress: 37.97%  Words/thread/sec: 410.61k  ead/sec: 410.58k  ogress: 39.19%  Words/thread/sec: 410.61k  48k  thread/sec: 410.94k  ss: 40.70%  Words/thread/sec: 411.03k   ords/thread/sec: 410.63k  4374  Progress: 42.52%  Words/thread/sec: 410.58k  ec: 410.62k  s: 43.73%  Words/thread/sec: 410.51k  0.013967  Progress: 44.14%  Words/thread/sec: 410.98k  ad/sec: 410.56k  gress: 45.36%  Words/thread/sec: 410.18k  0k    Words/thread/sec: 410.20k  : 410.36k  hread/sec: 410.01k  : 0.013029  Progress: 47.90%  Words/thread/sec: 410.08k  gress: 48.47%  Words/thread/sec: 409.91k  5%  Words/thread/sec: 409.94k   Words/thread/sec: 410.06k  410.08k  lpha: 0.012410  Progress: 50.39%  Words/thread/sec: 410.08k  10.21k  hread/sec: 409.97k  81%  Words/thread/sec: 410.33k  thread/sec: 410.38k  s: 51.65%  Words/thread/sec: 409.97k  ha: 0.011976  Progress: 52.11%  Words/thread/sec: 410.03k  2.64%  Words/thread/sec: 410.22k  ogress: 53.22%  Words/thread/sec: 410.07k  09k    Words/thread/sec: 409.93k    Progress: 54.52%  Words/thread/sec: 409.87k   0.011255  Progress: 54.99%  Words/thread/sec: 409.90k  rogress: 55.55%  Words/thread/sec: 410.03k  thread/sec: 410.03k  6.61%  Words/thread/sec: 410.06k    Words/thread/sec: 410.42k  s: 57.30%  Words/thread/sec: 410.30k  rds/thread/sec: 410.12k  221  Progress: 59.13%  Words/thread/sec: 409.99k  c: 410.21k  : 0.009899  Progress: 60.42%  Words/thread/sec: 410.17k   Progress: 60.62%  Words/thread/sec: 410.10k  09.94k  .84%  Words/thread/sec: 410.02k  a: 0.009391  Progress: 62.45%  Words/thread/sec: 410.04k  241  Progress: 63.05%  Words/thread/sec: 409.95k  : 63.46%  Words/thread/sec: 410.21k  .009068  Progress: 63.88%  Words/thread/sec: 410.56k  d/sec: 410.29k  ress: 65.08%  Words/thread/sec: 410.31k  k   Words/thread/sec: 410.12k  008275  Progress: 66.91%  Words/thread/sec: 410.25k  ha: 0.008236  Progress: 67.13%  Words/thread/sec: 410.37k  10.32k   410.09k  sec: 410.18k  rogress: 68.33%  Words/thread/sec: 410.08k  ec: 410.17k    0.007512  Progress: 69.98%  Words/thread/sec: 410.11k  lpha: 0.007407  Progress: 70.51%  Words/thread/sec: 410.54k  ords/thread/sec: 410.22k  71.29%  Words/thread/sec: 410.25k   a: 0.006913  Progress: 72.36%  Words/thread/sec: 410.28k  : 72.93%  Words/thread/sec: 410.19k  006645  Progress: 73.43%  Words/thread/sec: 410.33k  rogress: 73.78%  Words/thread/sec: 410.34k  73.99%  Words/thread/sec: 410.44k    Words/thread/sec: 410.21k  .006338  Progress: 74.66%  Words/thread/sec: 410.10k  1%  Words/thread/sec: 409.97k   0.005998  Progress: 76.02%  Words/thread/sec: 409.99k  ead/sec: 409.91k  77.03%  Words/thread/sec: 410.19k  rogress: 77.23%  Words/thread/sec: 410.08k  .04k  4%  Words/thread/sec: 410.16k   0.005231  Progress: 79.09%  Words/thread/sec: 410.19k  ead/sec: 410.27k  ogress: 80.35%  Words/thread/sec: 410.14k  pha: 0.004810  Progress: 80.77%  Words/thread/sec: 410.20k  /thread/sec: 410.25k    Progress: 82.00%  Words/thread/sec: 410.20k  410.15k  3.21%  Words/thread/sec: 410.16k  77%  Words/thread/sec: 410.43k  39k  ss: 84.40%  Words/thread/sec: 410.18k   410.35k   ds/thread/sec: 410.45k  read/sec: 410.46k  48k  1k   88.05%  Words/thread/sec: 410.32k  8  Progress: 88.54%  Words/thread/sec: 410.35k  a: 0.002731  Progress: 89.09%  Words/thread/sec: 410.33k  rds/thread/sec: 410.46k  Progress: 89.97%  Words/thread/sec: 410.45k  rogress: 90.44%  Words/thread/sec: 410.52k  2243  Progress: 91.04%  Words/thread/sec: 410.26k  410.42k  2.33%  Words/thread/sec: 410.37k  ha: 0.001768  Progress: 92.95%  Words/thread/sec: 410.49k  thread/sec: 410.48k   Progress: 94.15%  Words/thread/sec: 410.56k  10.54k  .37%  Words/thread/sec: 410.51k  a: 0.001010  Progress: 95.97%  Words/thread/sec: 410.51k  hread/sec: 410.44k  Progress: 97.19%  Words/thread/sec: 410.31k  0.46k  41%  Words/thread/sec: 410.32k  : 0.000242  Progress: 99.05%  Words/thread/sec: 410.57k  ec: 410.57k  "
     ]
    }
   ],
   "source": [
    "# Setup - train model \n",
    "word2vec.word2vec('example/data/text8', 'example/data/text8.bin', size=50, binary=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.load('example/data/text8.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is batman. Model did not recognize the word batwoman\n",
      "Correct answer is boy. Model guessed correctly.\n",
      "Correct answer is buck. Model guessed gen\n",
      "Correct answer is businessman. Model guessed lev\n",
      "Correct answer is dad. Model did not recognize the word chairwoman\n",
      "Correct answer is duke. Model guessed grand\n",
      "Correct answer is father. Model guessed correctly.\n",
      "Correct answer is fox. Model did not recognize the word fisherwoman\n",
      "Correct answer is god. Model did not recognize the word gentlewoman\n",
      "Correct answer is grandpa. Model guessed poulenc\n",
      "Correct answer is groom. Model guessed son\n",
      "Correct answer is heir. Model did not recognize the word headmistress\n",
      "Correct answer is hound. Model guessed spider\n",
      "Correct answer is king. Model guessed correctly.\n",
      "Correct answer is man. Model did not recognize the word lioness\n",
      "Correct answer is mister. Model did not recognize the word missis\n",
      "Correct answer is nephew. Model did not recognize the word murderess\n",
      "Correct answer is policeman. Model did not recognize the word policewoman\n",
      "Correct answer is ram. Model guessed fulani\n",
      "Correct answer is sculptor. Model did not recognize the word sculptress\n",
      "Correct answer is son. Model guessed correctly.\n",
      "Correct answer is stepfather. Model guessed drusilla\n",
      "Correct answer is tiger. Model did not recognize the word superwoman\n",
      "Correct answer is valet. Model did not recognize the word maidservant\n",
      "Correct answer is webmaster. Model did not recognize the word webmistress\n",
      "Accuracy rate:  16.0 %\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "countTotal = 0\n",
    "correctCount = 0\n",
    "incorrectCount = 0\n",
    "unrecognizedCount = 0\n",
    "\n",
    "# Change file name to run experiment on different analogy sets \n",
    "with open('./Bigger Analogy Test Set/3_Encyclopedic_semantics/E10 [male - female].txt') as file:\n",
    "    for line1,line2 in itertools.zip_longest(*[file]*2):\n",
    "        line1 = line1.split('\\t')\n",
    "        line2 = line2.split('\\t')\n",
    "        line1[1] = line1[1].split('/')\n",
    "        for i in range(len(line1[1])):\n",
    "            line1[1][i] = line1[1][i].rstrip()\n",
    "            if line1[1][i].__contains__('-'):\n",
    "                line1[1].pop(i)\n",
    "        line2[1] = line2[1].split('/')\n",
    "        for i in range(len(line2[1])):\n",
    "            line2[1][i] = line2[1][i].rstrip()\n",
    "            if line2[1][i].__contains__('-'):\n",
    "                line2[1].pop(i)\n",
    "        countTotal += 1\n",
    "        try:\n",
    "            line2[1].append(line1[0])\n",
    "            indexes, metrics = model.analogy(pos=line2[1], neg=line1[1])\n",
    "            if (model.vocab[indexes].__contains__(line2[0])):\n",
    "                correctCount += 1\n",
    "                print(\"Correct answer is \" + line2[0] + \". Model guessed correctly.\")\n",
    "            else:\n",
    "                incorrectCount += 1\n",
    "                print(\"Correct answer is \" + line2[0] + \". Model guessed \" + model.vocab[indexes][0])\n",
    "        except Exception as e:\n",
    "             unrecognizedCount += 1\n",
    "             print(\"Correct answer is \" + line2[0] + \". Model did not recognize the word \" + e.args[0])\n",
    "        #print(line1[0], line1[1], line2[0], line2[1])\n",
    "    print(\"Accuracy rate: \", correctCount/countTotal*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Accuracy':['Accurate Guess', 'Related Guess', 'Incorrect Guess', 'Not Recognized'], 'Number of Guesses':[correctCount, 6, incorrectCount, unrecognizedCount]})\n",
    "ax = df.plot.bar(x='Accuracy', y='Number of Guesses', rot=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Takeaways\n",
    "\n",
    "1. The model seems to perform much better on the **inflectional morphology** dataset. \n",
    "- This is likely an inherent quality of the word2vec model. \n",
    "- For context: **inflectional morphology** does not change the part of speech of a word, and is associated with relationships *between* words (ex. changing a verb from its singular form to plural form in order to match the subject of a sentence). In contrast, **derivational morphology** can often change the part of speech of a word, and is associated with semantic relationships *within* a word itself (ex. changing a verb to an adverb usually has no relationship to the rest of a sentence). [See this handout for more info.](http://websites.umich.edu/~jlawler/Inflection.pdf)\n",
    "- Because word2vec compares relationships *between* words, it seems inherently better suited to analyze these types of analogies. \n",
    "2. The impact of bias/variance can be seen in the results comparing accuracy across dimensional values. \n",
    "- In the case of 5-dimension vectors, the vectors are really too small to be of much use, resulting in extremely poor results (never scoring above 4% accuracy). The model is unable to distinguish relevant relationships between the words because the vectors are so small, resulting in a high degree of *bias*. Increasing the dimensions to 50 helps significantly, but issues still persist. \n",
    "- However, beyond about 1000-dimension vectors does not seem to increase the accuracy of the results and in fact seems to worsen the accuracy in certain cases. This is likely due to overfitting or *bias* with such large vectors. \n",
    "- Overall, anywhere from 500-1500 dimension vectors will likely provide a suitable model. \n",
    "3. The model's results are ***heavily*** dependent on the training data set. \n",
    "- Certain analogy sets were not usable because the words used did not appear in the training set, resulting in complete failure. \n",
    "- However, beyond just not including words in the training set, some relationships were indiscernable even if all words were in the training set. \n",
    "- An example of this is the UK city -> County data set, which associates cities in the UK with the county they are located in. The model recognized every word used in every analogy. However, the training set likely did not include any sentences indicating the relationship between these words as cities/counties, and thus the model was never able to get any of the analogies correct. \n",
    "- This has probably been discussed at length for machine learning algorithms in general, but still an important reminder that the biases present in the training data sets for these models will become very apparent when putting them into practice. Thus it is important to use a diverse and varied data set for these types of algorithms. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
